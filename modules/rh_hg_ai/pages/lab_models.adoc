= The Granite Model Family

This course will utilize models from the Granite family, a series of enterprise-grade, open-source Large Language Models (LLMs) developed by IBM. This section provides an overview of the Granite models and details the specific model we will use in our labs.

== Introducing Granite: Enterprise-Ready AI Models

Granite is a family of foundation models designed to support a wide range of generative AI use cases involving language, code, and vision. Developed by IBM, these models are built with enterprise applications in mind, emphasizing trust, transparency, and performance.

Key characteristics of the Granite model family include:

* **Open Source:** All Granite models are released under the permissive `Apache 2.0` license. This allows developers and organizations to freely use, modify, and distribute the models, making them ideal for environments where data sensitivity requires a self-hosted LLM.
* **Transparent Training Data:** IBM discloses the training data for Granite models, fostering trust and enabling better evaluation for enterprise-specific use cases.
* **Purpose-Built:** The Granite family includes a diverse set of models, each optimized for specific tasks, from code generation and text summarization to document understanding and time-series forecasting.

== The Granite Model Ecosystem

The Granite family is composed of several specialized model types, each tailored for different enterprise needs.

[cols="1,2"]
|===
| Model Type | Description

| *Language Models*
| Base and instruction-tuned models with advanced reasoning capabilities. Designed for agentic workflows, Retrieval-Augmented Generation (RAG), text analytics, classification, and content generation.

| *Vision Models*
| Pre-trained models specialized in vision tasks for document and image understanding. They support a range of file types and are optimized for efficient deployment.

| *Speech Models*
| Compact and efficient speech-to-text models for transcription and translation tasks, supporting English and seven other languages.

| *Time Series Models*
| Lightweight, pre-trained models for time-series forecasting, optimized to run efficiently across various hardware configurations.

| *Embedding Models*
| Designed to enhance the understanding of user intent and improve the relevance of information retrieved in RAG and semantic search applications.

| *Geospatial Models*
| A specialized foundation model developed in partnership with NASA, trained on large-scale satellite and remote sensing data for Earth observations.

| *Granite Guardian*
| A model focused on AI safety, designed to mitigate risks by safeguarding against problematic user prompts and ensuring secure LLM responses. It has demonstrated top performance across numerous safety benchmarks.
|===

== Focus Model: `ibm-granite/granite-3.3-2b-instruct`

Throughout this course, we will primarily use the `ibm-granite/granite-3.3-2b-instruct` model.

=== Rationale for Selection

The selection of this model was deliberate for several key reasons relevant to this course's learning objectives:

. **Quantization Labs:** It is a full-sized base model, making it an excellent candidate for our future labs on model quantization. This allows us to demonstrate the process of reducing a model's footprint for more efficient deployment.
. **Performance and Size:** As a 2-billion parameter model, it strikes a balance between performance and resource requirements. It is small enough to be uploaded and deployed for inference relatively quickly, even in resource-constrained environments.
. **Generational Comparison:** With the recent release of the Granite 4 series, using a 3.3 generation model provides a perfect baseline. This will enable a future lab where we can directly compare the performance gains between model generations, a common task in production environments.

From hands-on experience during the development of this course, the `granite-3.3-2b-instruct` model has consistently provided correct and relevant answers. Its large 128K context window, paired with its relatively small size, allows for ample performance on a single 24GB GPU.

=== Model Details: `Granite-3.3-2B-Instruct`

Here is a summary of the key details for our focus model.

* **Developers:** Granite Team, IBM
* **Hugging Face ID:** `ibm-granite/granite-3.3-2b-instruct`
* **GitHub Repository:** link:https://github.com/ibm-granite/granite-3.3-language-models[ibm-granite/granite-3.3-language-models]
* **Release Date:** April 16th, 2025
* **License:** `Apache 2.0`
* **Supported Languages:** Primarily English, with capabilities in German, Spanish, French, Japanese, Portuguese, Arabic, Czech, Italian, Korean, Dutch, and Chinese. The model can be fine-tuned for additional languages.

==== Intended Use and Capabilities

This model is designed for general instruction-following tasks and can be integrated into AI assistants across various domains. Its capabilities include:

* Summarization
* Text Classification & Extraction
* Question Answering (QA)
* Retrieval-Augmented Generation (RAG)
* Code Generation & Function-Calling
* Multilingual Dialog
* Long-Context Tasks (e.g., document summarization, meeting analysis)

A notable feature is its support for structured reasoning through `<think>` and `<response>` tags, which provides a clear separation between the model's internal "thought process" and the final output it generates.